# coding: utf-8

"""
    OpenAI API

    The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.

    The version of the OpenAPI document: 2.3.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json




from pydantic import BaseModel, Field, StrictFloat, StrictInt, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional, Union
from openapi_server.models.realtime.realtime_session_input_audio_transcription import RealtimeSessionInputAudioTranscription
from openapi_server.models.realtime.realtime_session_max_response_output_tokens import RealtimeSessionMaxResponseOutputTokens
from openapi_server.models.realtime.realtime_session_tools_inner import RealtimeSessionToolsInner
from openapi_server.models.realtime.realtime_session_turn_detection import RealtimeSessionTurnDetection
try:
    from typing import Self
except ImportError:
    from typing_extensions import Self

class RealtimeSession(BaseModel):
    """
    Realtime session object configuration.
    """ # noqa: E501
    modalities: Optional[List[StrictStr]] = Field(default=None, description="The set of modalities the model can respond with. To disable audio, set this to [\"text\"]. ")
    instructions: Optional[StrictStr] = Field(default=None, description="The default system instructions (i.e. system message) prepended to model  calls. This field allows the client to guide the model on desired  responses. The model can be instructed on response content and format,  (e.g. \"be extremely succinct\", \"act friendly\", \"here are examples of good  responses\") and on audio behavior (e.g. \"talk quickly\", \"inject emotion  into your voice\", \"laugh frequently\"). The instructions are not guaranteed  to be followed by the model, but they provide guidance to the model on the  desired behavior.  Note that the server sets default instructions which will be used if this  field is not set and are visible in the `session.created` event at the  start of the session. ")
    voice: Optional[StrictStr] = Field(default=None, description="The voice the model uses to respond. Supported voices are `alloy`, `ash`, `ballad`, `coral`, `echo`, `sage`, `shimmer`, and `verse`. Cannot be  changed once the model has responded with audio at least once. ")
    input_audio_format: Optional[StrictStr] = Field(default=None, description="The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. ")
    output_audio_format: Optional[StrictStr] = Field(default=None, description="The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. ")
    input_audio_transcription: Optional[RealtimeSessionInputAudioTranscription] = None
    turn_detection: Optional[RealtimeSessionTurnDetection] = None
    tools: Optional[List[RealtimeSessionToolsInner]] = Field(default=None, description="Tools (functions) available to the model.")
    tool_choice: Optional[StrictStr] = Field(default=None, description="How the model chooses tools. Options are `auto`, `none`, `required`, or  specify a function. ")
    temperature: Optional[Union[StrictFloat, StrictInt]] = Field(default=None, description="Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8. ")
    max_response_output_tokens: Optional[RealtimeSessionMaxResponseOutputTokens] = None
    __properties: ClassVar[List[str]] = ["modalities", "instructions", "voice", "input_audio_format", "output_audio_format", "input_audio_transcription", "turn_detection", "tools", "tool_choice", "temperature", "max_response_output_tokens"]

    @field_validator('voice')
    def voice_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in ('alloy', 'ash', 'ballad', 'coral', 'echo', 'sage', 'shimmer', 'verse',):
            raise ValueError("must be one of enum values ('alloy', 'ash', 'ballad', 'coral', 'echo', 'sage', 'shimmer', 'verse')")
        return value

    model_config = {
        "populate_by_name": True,
        "validate_assignment": True,
        "protected_namespaces": (),
    }


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Self:
        """Create an instance of RealtimeSession from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        _dict = self.model_dump(
            by_alias=True,
            exclude={
            },
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of input_audio_transcription
        if self.input_audio_transcription:
            _dict['input_audio_transcription'] = self.input_audio_transcription.to_dict()
        # override the default output from pydantic by calling `to_dict()` of turn_detection
        if self.turn_detection:
            _dict['turn_detection'] = self.turn_detection.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in tools (list)
        _items = []
        if self.tools:
            for _item in self.tools:
                if _item:
                    _items.append(_item.to_dict())
            _dict['tools'] = _items
        # override the default output from pydantic by calling `to_dict()` of max_response_output_tokens
        if self.max_response_output_tokens:
            _dict['max_response_output_tokens'] = self.max_response_output_tokens.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Dict) -> Self:
        """Create an instance of RealtimeSession from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "modalities": obj.get("modalities"),
            "instructions": obj.get("instructions"),
            "voice": obj.get("voice"),
            "input_audio_format": obj.get("input_audio_format"),
            "output_audio_format": obj.get("output_audio_format"),
            "input_audio_transcription": RealtimeSessionInputAudioTranscription.from_dict(obj.get("input_audio_transcription")) if obj.get("input_audio_transcription") is not None else None,
            "turn_detection": RealtimeSessionTurnDetection.from_dict(obj.get("turn_detection")) if obj.get("turn_detection") is not None else None,
            "tools": [RealtimeSessionToolsInner.from_dict(_item) for _item in obj.get("tools")] if obj.get("tools") is not None else None,
            "tool_choice": obj.get("tool_choice"),
            "temperature": obj.get("temperature"),
            "max_response_output_tokens": RealtimeSessionMaxResponseOutputTokens.from_dict(obj.get("max_response_output_tokens")) if obj.get("max_response_output_tokens") is not None else None
        })
        return _obj


